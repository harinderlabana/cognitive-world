<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>Cognitive World</title>

    <!--A-Frame Library-->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>

    <!--User Interface Styling-->
    <style>
      .ui-overlay {
        position: absolute;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        z-index: 10;
        text-align: center;
        color: white;
        font-family: sans-serif;
      }
      .status-box {
        background-color: rgba(0, 0, 0, 0.6);
        padding: 12px 24px;
        border-radius: 12px;
        margin-bottom: 15px;
      }
      .control-button {
        background-color: #4a4e69;
        color: white;
        padding: 15px 30px;
        border-radius: 50px;
        border: none;
        font-size: 1.2em;
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <!--Define the 3D Scene-->
    <a-scene renderer="colorManagement: true">
      <a-assets timeout="10000">
        <img
          id="sky-asset"
          src="https://raw.githubusercontent.com/aframevr/aframe/master/examples/boilerplate/panorama/puydesancy.jpg"
          crossorigin="anonymous"
        />
      </a-assets>

      <a-light type="ambient" color="#FFF" intensity="1.0"></a-light>
      <a-sky id="sky-background" color="#101015"></a-sky>

      <!-- We're updating the default text to be a title and a prompt for the user. -->
      <a-text
        id="main-text"
        value="Cognitive World"
        position="-2.5 2.2 -5"
        color="#FFFFFF"
      ></a-text>
      <a-text
        id="sub-text"
        value="Click the button to begin."
        position="-2.5 1.8 -5"
        color="#CCCCCC"
      ></a-text>

      <a-camera></a-camera>
    </a-scene>

    <!--Button and Status Box-->
    <div class="ui-overlay">
      <div id="status-display" class="status-box">Status: Ready to Test</div>
      <!-- The button now calls startListening() and has new text. -->
      <button id="mic-button" class="control-button" onclick="startListening()">
        Start Listening
      </button>
    </div>

    <!--Interactive JavaScript-->
    <script>
      function changeSky(assetId) {
        const skyElement = document.querySelector("#sky-background");
        if (skyElement) {
          skyElement.setAttribute("material", "src", assetId);
          skyElement.setAttribute("material", "color", "#FFFFFF");
        }
      }

      // --- [ Section 2: Voice Recognition ] ---

      // We check if the browser supports the Web Speech API. It's called 'webkitSpeechRecognition' in Chrome and Edge.
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;

      // We'll create a variable to hold our recognition "engine".
      let recognition;

      // We only proceed if the browser actually supports this feature.
      if (SpeechRecognition) {
        recognition = new SpeechRecognition();

        // These settings configure the recognition engine.
        recognition.continuous = false; // We want it to stop after we finish speaking.
        recognition.lang = "en-US"; // Set the language.
        recognition.interimResults = false; // We only want the final, confident result.

        // This event fires when the recognition engine has a final result.
        recognition.onresult = function (event) {
          // We get the spoken text from the event.
          const transcript = event.results[0][0].transcript.trim();

          // For now, we'll just log it to the console and update our 3D text.
          console.log("I heard you say:", transcript);
          document.querySelector(
            "#status-display"
          ).textContent = `Heard: "${transcript}"`;
          document
            .querySelector("#main-text")
            .setAttribute("value", "Processing command...");

          // --- THIS IS THE CRITICAL CONNECTION ---
          // We will now check if the user said our magic word, "begin".
          if (transcript.toLowerCase() === "begin") {
            document
              .querySelector("#main-text")
              .setAttribute("value", "Command recognized!");
            // If they did, we call our trusted changeSky function!
            changeSky("#sky-asset");
          } else {
            document
              .querySelector("#main-text")
              .setAttribute("value", "Command not recognized.");
          }
        };

        // This event fires if there's an error.
        recognition.onerror = function (event) {
          console.error("Speech recognition error:", event.error);
          document.querySelector(
            "#status-display"
          ).textContent = `Error: ${event.error}`;
        };
      } else {
        // If the browser doesn't support the API, we'll show an error.
        console.error("Speech Recognition not supported in this browser.");
        document.querySelector("#status-display").textContent =
          "Error: Voice commands not supported here.";
      }

      // This is the new function that our button will call.
      function startListening() {
        if (recognition) {
          document.querySelector("#status-display").textContent =
            "Status: Listening...";
          recognition.start(); // This command activates the microphone.
        }
      }
    </script>
  </body>
</html>
